{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4448acd",
   "metadata": {},
   "source": [
    "Importing cv2 (i.e. computer vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7700d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b994e",
   "metadata": {},
   "source": [
    "## Learning how to read images, videos and webcam ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c86922",
   "metadata": {},
   "source": [
    "#### how to import an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65e6e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img= cv2.imread(\"resources/lena.png\")\n",
    "\n",
    "cv2.imshow(\"output\", img)\n",
    "cv2.waitKey(0) #to cause delay in output , if value is 0, then infinitely delayed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f936103a",
   "metadata": {},
   "source": [
    "#### how to import a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6bd0b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     success, img \u001b[38;5;241m=\u001b[39mcap\u001b[38;5;241m.\u001b[39mread()   \u001b[38;5;66;03m#variable 'success' is a boolean var\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVideo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "cap= cv2.VideoCapture(\"resources/test_video1.mp4\")\n",
    "\n",
    "while True:\n",
    "    success, img =cap.read()   #variable 'success' is a boolean var\n",
    "    cv2.imshow(\"Video\", img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dcbee4",
   "metadata": {},
   "source": [
    "#### how to use ur webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e55e5d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,640)       #width\n",
    "cap.set(4,480)       #length\n",
    "\n",
    "while True:\n",
    "    success, img =cap.read()   #variable 'success' is a boolean var\n",
    "    cv2.imshow(\"Video\", img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778e5f7",
   "metadata": {},
   "source": [
    "## Basic Functions\n",
    "\n",
    "#### 1. COLOR_BGR2GRAY- converts to gray \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8575915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img= cv2.imread(\"resources/lena.png\")\n",
    "\n",
    "imgGray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray Image\", imgGray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d9329",
   "metadata": {},
   "source": [
    "#### 2.GaussianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77486e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgBlur = cv2.GaussianBlur(imgGray, (21,21), 0)  # odd no.s only for (.,.)\n",
    "\n",
    "cv2.imshow(\"Gray Image\", imgGray)\n",
    "cv2.imshow(\"Blur Image\", imgBlur)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c94147",
   "metadata": {},
   "source": [
    "#### 3.Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fd86569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgCanny= cv2.Canny(img, 150,200)\n",
    "cv2.imshow(\"Canny img\", imgCanny)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f75713",
   "metadata": {},
   "source": [
    "#### 4.Dilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91418ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel=np.ones((5,5), np.uint8)\n",
    "imgDilate=cv2.dilate(imgCanny, kernel, iterations=1) #increasing iteration increases edge thickness\n",
    "cv2.imshow(\"Dilated Image\", imgDilate)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4224f9",
   "metadata": {},
   "source": [
    "#### 5. Erode - opp of dilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbcb16ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgEroded=cv2.erode(imgDilate, kernel, iterations=1)\n",
    "cv2.imshow(\"Eroded image\", imgEroded)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3964cf2",
   "metadata": {},
   "source": [
    "#### Resizing our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ffda37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 623, 3)\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"resources/lambo.png\")\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac97ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgResize= cv2.resize(img, (300,200))   # (width,height)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"resized image\", imgResize)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e10eef",
   "metadata": {},
   "source": [
    "#### Cropping our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9768c358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgCropped = img[0:200, 200:500]  #[height, width]\n",
    "cv2.imshow(\"Cropped image\", imgCropped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf52886",
   "metadata": {},
   "source": [
    "## Shape and Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dbb946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=np.zeros((512, 512, 3), np.uint8)\n",
    "print(img)\n",
    "\n",
    " #img[200:300, 100:300]= 0, 255 ,0  #B, G, R\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b427838",
   "metadata": {},
   "source": [
    "#### 1.creating a line in the image\n",
    "#### 2.Creating a rectangle in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f6a4fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.line(img, (0,0), (300,300),(0,255,0), 3)\n",
    "cv2.line(img, (0,0), (img.shape[1], img.shape[0]),(0,255,0), 3)\n",
    "cv2.rectangle(img, (0,0), (250,350), (0,0,255), 2) # For bordered rectangle\n",
    "\n",
    "# for fully coloured rectangle , use cv2.FILLED instead of thickness\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c78123",
   "metadata": {},
   "source": [
    "#### 3.Creating a circle in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "477d95ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format:-  cv2.circle(img, center, radius, color, thickness)\n",
    "cv2.circle(img, (400,50), 30, (255,255,0), 5)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb32b08",
   "metadata": {},
   "source": [
    "#### 4.Putting text on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a027a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.putText(img, \"Hello world\", (300,200), cv2.FONT_HERSHEY_COMPLEX, 1, (0,150,0), 1)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416bea66",
   "metadata": {},
   "source": [
    "## Warp Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(\"resources/cards.jpg\")\n",
    "\n",
    "width, height = 250, 350\n",
    "pts1= np.float32([[111,219], [287,188],[154,482], [352,440]])  #find points of pixel through mspaint\n",
    "pts2= np.float32([[0,0], [width,0], [0,height], [width,height]])\n",
    "matrix=cv2.getPerspectiveTransform(pts1, pts2)\n",
    "imgwarp= cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"output\", imgwarp)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11932bb",
   "metadata": {},
   "source": [
    "## Joining Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45d4625c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"resources/lena.png\")\n",
    "\n",
    "imghor = np.hstack((img, img))\n",
    "imgver= np.vstack((img,img))\n",
    "\n",
    "cv2.imshow(\"horizontal\", imghor)\n",
    "cv2.imshow(\"vertical\", imgver)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46183ac1",
   "metadata": {},
   "source": [
    "## Color Detection\n",
    "\n",
    "#### TASK: To detect orange colour in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e056a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"resources/lambo.png\"\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Trackbars\")\n",
    "cv2.resizeWindow(\"Trackbars\", 640, 240)\n",
    "cv2.createTrackbar(\"Hue Min\", \"Trackbars\", 3, 179, empty)\n",
    "cv2.createTrackbar(\"Hue Max\", \"Trackbars\", 17, 179, empty)\n",
    "cv2.createTrackbar(\"Sat Min\", \"Trackbars\", 140, 255, empty)\n",
    "cv2.createTrackbar(\"Sat Max\", \"Trackbars\", 255, 255, empty)\n",
    "cv2.createTrackbar(\"Val Min\", \"Trackbars\", 147, 255, empty)\n",
    "cv2.createTrackbar(\"Val Max\", \"Trackbars\", 255, 255, empty)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    img = cv2.imread(path)\n",
    "    imgHSV= cv2.cvtColor(img , cv2.COLOR_BGR2HSV)\n",
    "    h_min=cv2.getTrackbarPos(\"Hue Min\", \"Trackbars\")\n",
    "    h_max=cv2.getTrackbarPos(\"Hue Max\", \"Trackbars\")\n",
    "    s_min=cv2.getTrackbarPos(\"Sat Min\", \"Trackbars\")\n",
    "    s_max=cv2.getTrackbarPos(\"Sat Max\", \"Trackbars\")\n",
    "    v_min=cv2.getTrackbarPos(\"Val Min\", \"Trackbars\")\n",
    "    v_max=cv2.getTrackbarPos(\"Val Max\", \"Trackbars\")\n",
    "    \n",
    "    lower=np.array([h_min, s_min, v_min])\n",
    "    upper= np.array([h_max, s_max, v_max])\n",
    "    mask=cv2.inRange(imgHSV, lower, upper)\n",
    "    imgRes= cv2.bitwise_and(img, img , mask=mask)\n",
    "    \n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.imshow(\"HSV\", imgHSV)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Result\", imgRes)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fde6418",
   "metadata": {},
   "source": [
    "## Contours and shape detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d366c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3593.5\n",
      "8619.0\n",
      "10398.5\n",
      "10236.0\n",
      "1612.5\n",
      "10402.0\n",
      "6389.0\n",
      "5629.0\n",
      "3475.5\n",
      "2270.5\n",
      "3552.5\n",
      "8674.0\n",
      "2646.0\n",
      "5690.5\n",
      "10234.0\n",
      "5712.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "\n",
    "def getContours(img):\n",
    "    contours, heirarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area= cv2.contourArea(cnt)\n",
    "        print(area)\n",
    "        if area>500:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255,0,0), 3)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            # print(peri)\n",
    "            approx= cv2.approxPolyDP(cnt, 0.02*peri, True)\n",
    "            # print(len(approx))\n",
    "            objCor= len(approx)\n",
    "            x,y, w, h = cv2.boundingRect(approx)\n",
    "            \n",
    "            if objCor==3:objectType='Tri'\n",
    "            elif objCor==4:\n",
    "                aspRatio=w/float(h)\n",
    "                if aspRatio>0.95 and aspRatio<1.05:\n",
    "                    objectType='square'\n",
    "                else:objectType='Rect'\n",
    "            elif objCor>4 : objectType='Circle'\n",
    "            else: objectType='None'\n",
    "            cv2.rectangle(imgContour, (x,y), (x+w, y+h), (0, 255,0), 2)\n",
    "            cv2.putText(imgContour, objectType, (x+(w//2)-10, y+(h//2)-10), cv2.FONT_HERSHEY_COMPLEX,0.7, (0, 0,0),2)\n",
    "                        \n",
    "                        \n",
    "path=\"resources/shapes.png\"\n",
    "img= cv2.imread(path)\n",
    "imgContour = img.copy()\n",
    "\n",
    "imgGray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgBlur=cv2.GaussianBlur(imgGray,(7,7), 1)\n",
    "imgcanny=cv2.Canny(imgBlur, 50,50)\n",
    "imgblank= np.zeros_like(img)\n",
    "getContours(imgcanny)\n",
    "\n",
    "imgstack= stackImages(0.8, ([img, imgGray, imgBlur], [imgcanny, imgContour,imgblank]))\n",
    "imgstack= cv2.resize(imgstack, (640, 480))\n",
    "\n",
    "#cv2.imshow(\"Original\", img)\n",
    "#cv2.imshow(\"Gray\", imgGray)\n",
    "#cv2.imshow(\"Blur\", imgBlur)\n",
    "cv2.imshow(\"Stacked\", imgstack)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778a0cc",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd725800",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade=  cv2.CascadeClassifier(\"resources/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "img = cv2.imread(\"resources/lena.png\")\n",
    "imgGray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces= faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img , (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    \n",
    "cv2.imshow(\"Result\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502f990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
